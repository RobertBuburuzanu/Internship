{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ee5992a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\rober\\anaconda3\\lib\\site-packages (4.9.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rober\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\rober\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\rober\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\rober\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rober\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32ff793e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting undetected-chromedriver\n",
      "  Downloading undetected-chromedriver-3.4.6.tar.gz (61 kB)\n",
      "Requirement already satisfied: selenium>=4.0.0 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from undetected-chromedriver) (4.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\rober\\anaconda3\\lib\\site-packages (from undetected-chromedriver) (2.27.1)\n",
      "Collecting websockets\n",
      "  Downloading websockets-11.0.3-cp39-cp39-win_amd64.whl (124 kB)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from selenium>=4.0.0->undetected-chromedriver) (0.10.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from selenium>=4.0.0->undetected-chromedriver) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from selenium>=4.0.0->undetected-chromedriver) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from selenium>=4.0.0->undetected-chromedriver) (0.22.0)\n",
      "Requirement already satisfied: idna in c:\\users\\rober\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.0.0->undetected-chromedriver) (3.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.0.0->undetected-chromedriver) (21.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.0.0->undetected-chromedriver) (1.1.1)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\rober\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.0.0->undetected-chromedriver) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rober\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.0.0->undetected-chromedriver) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.0.0->undetected-chromedriver) (1.15.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\rober\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.0.0->undetected-chromedriver) (1.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.0.0->undetected-chromedriver) (1.10)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rober\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium>=4.0.0->undetected-chromedriver) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium>=4.0.0->undetected-chromedriver) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium>=4.0.0->undetected-chromedriver) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium>=4.0.0->undetected-chromedriver) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\rober\\anaconda3\\lib\\site-packages (from requests->undetected-chromedriver) (2.0.4)\n",
      "Building wheels for collected packages: undetected-chromedriver\n",
      "  Building wheel for undetected-chromedriver (setup.py): started\n",
      "  Building wheel for undetected-chromedriver (setup.py): finished with status 'done'\n",
      "  Created wheel for undetected-chromedriver: filename=undetected_chromedriver-3.4.6-py3-none-any.whl size=44498 sha256=043d37bdbc2f04191c9924dc7160f6130e0c89ce94fa6f54590bcd4f965f16ba\n",
      "  Stored in directory: c:\\users\\rober\\appdata\\local\\pip\\cache\\wheels\\59\\91\\0c\\e10481bbb66f4c4b09cc2aa1356320fafc24cc7be7f9563e73\n",
      "Successfully built undetected-chromedriver\n",
      "Installing collected packages: websockets, undetected-chromedriver\n",
      "Successfully installed undetected-chromedriver-3.4.6 websockets-11.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install undetected-chromedriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c89c876",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f70d7cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import undetected_chromedriver as uc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05522836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first connect to the driver \n",
    "# I had to use a different tool because webdriver didint allow me to acces\n",
    "#the website when I run search.click() line.It said \"Acces Denied\"\n",
    "driver = uc.Chrome()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35cf9f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f8a6719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required in the question\n",
    "designation = driver.find_element(By.CLASS_NAME, 'suggestor-input')\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5af16bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH, '/html/body/div/div[7]/div/div/div[5]/div/div/div/div[1]/div/input')\n",
    "location.send_keys('Bangalore/Bengaluru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d937531",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME, 'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b327a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd43d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from the given page\n",
    "title_tags = driver.find_elements(By.XPATH, '//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a61a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tags = driver.find_elements(By.XPATH, '//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fb2104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tags = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d2499f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_tags = driver.find_elements(By.XPATH, '//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aa18620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6d0e366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Temp. WFH - Bangalore/Bengaluru, Noida, Pune, ...</td>\n",
       "      <td>Infogain</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>S&amp;P Global Inc.</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Banking Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, G...</td>\n",
       "      <td>Coforge</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Title  \\\n",
       "0                      Data Analyst   \n",
       "1                      Data Analyst   \n",
       "2  Data Analyst - IIT/BITS/Startups   \n",
       "3            Data Analyst - FinTech   \n",
       "4            Data Analyst - FinTech   \n",
       "5            Data Analyst - FinTech   \n",
       "6  Data Analyst - IIT/BITS/Startups   \n",
       "7                      Data Analyst   \n",
       "8                      Data Analyst   \n",
       "9              Banking Data Analyst   \n",
       "\n",
       "                                            Location     Company_name  \\\n",
       "0                                Bangalore/Bengaluru              ANZ   \n",
       "1                                Bangalore/Bengaluru              ANZ   \n",
       "2                                Bangalore/Bengaluru     AVE Promagne   \n",
       "3  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...     Primo Hiring   \n",
       "4  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...     Primo Hiring   \n",
       "5  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...     Primo Hiring   \n",
       "6                                Bangalore/Bengaluru     AVE Promagne   \n",
       "7  Temp. WFH - Bangalore/Bengaluru, Noida, Pune, ...         Infogain   \n",
       "8                                Bangalore/Bengaluru  S&P Global Inc.   \n",
       "9  Bangalore/Bengaluru, Hyderabad/Secunderabad, G...          Coforge   \n",
       "\n",
       "  Experience  \n",
       "0    6-9 Yrs  \n",
       "1   6-10 Yrs  \n",
       "2    1-5 Yrs  \n",
       "3    1-2 Yrs  \n",
       "4    1-2 Yrs  \n",
       "5    1-2 Yrs  \n",
       "6    1-5 Yrs  \n",
       "7    4-7 Yrs  \n",
       "8    1-4 Yrs  \n",
       "9   5-10 Yrs  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Title':job_title, 'Location':job_location, 'Company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa2bb4b",
   "metadata": {},
   "source": [
    "Q2:Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results youget.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3bf5d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = uc.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bc6c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b46651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = driver.find_element(By.CLASS_NAME, 'suggestor-input')\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b00263f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH, '/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input')\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b330184",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME, 'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2b4e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4ea2af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags = driver.find_elements(By.XPATH, '//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH, '//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "company_tags = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae033e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "055aff71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manager, Data Solution Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, New Delhi</td>\n",
       "      <td>Pfizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist_NLP</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Persistent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Permanent Opportunity For Data scientist with AWS</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Chennai, Coimbat...</td>\n",
       "      <td>Deloitte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infosys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R&amp;D Specialist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Nokia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist- Bangalore</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Trigent Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                  Manager, Data Solution Specialist   \n",
       "2                                 Data Scientist_NLP   \n",
       "3                    Machine Learning (AI) Architect   \n",
       "4  Permanent Opportunity For Data scientist with AWS   \n",
       "5                                     Data Scientist   \n",
       "6                                     R&D Specialist   \n",
       "7                          Data Scientist- Bangalore   \n",
       "8                               Data Science Analyst   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                            Location       Company Name  \n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...          Accenture  \n",
       "1             Bangalore/Bengaluru, Mumbai, New Delhi             Pfizer  \n",
       "2  Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...  Fractal Analytics  \n",
       "3  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...         Persistent  \n",
       "4  Hybrid - Bangalore/Bengaluru, Chennai, Coimbat...           Deloitte  \n",
       "5                                Bangalore/Bengaluru            Infosys  \n",
       "6                                Bangalore/Bengaluru              Nokia  \n",
       "7                                Bangalore/Bengaluru   Trigent Software  \n",
       "8                                Bangalore/Bengaluru          Accenture  \n",
       "9                                Bangalore/Bengaluru                IBM  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Title':job_title,'Location':job_location,'Company Name':company_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988da06e",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get thewebpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results youget.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ff7e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = uc.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0458c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a47c1fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = driver.find_element(By.CLASS_NAME,'suggestor-input ')\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a19f148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME, 'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b23daa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_filter = driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]')\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06580d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_filter = driver.find_element(By.XPATH, '/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[6]/div[2]/div[3]/label/p/span[1]')\n",
    "location_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a9ad487",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c4cbbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags = driver.find_elements(By.XPATH, '//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH, '//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "company_tags = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "experience_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp = i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "79dc33d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4f9a0b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manager, Data Solution Specialist</td>\n",
       "      <td>Mumbai, New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Pfizer</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Blackbuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, United States (USA), Bulgaria</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - II (Contract)</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Netomi</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Gujarat Fluorochemicals</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Research Scientist - Bioinformatics</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Biopeople India</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - I</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Netomi</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Profit By Outsourcing</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title  \\\n",
       "0    Manager, Data Solution Specialist   \n",
       "1                Junior Data Scientist   \n",
       "2                       Data Scientist   \n",
       "3                       Data Scientist   \n",
       "4                Junior Data Scientist   \n",
       "5       Data Scientist - II (Contract)   \n",
       "6                       Data Scientist   \n",
       "7  Research Scientist - Bioinformatics   \n",
       "8                   Data Scientist - I   \n",
       "9            Machine Learning Engineer   \n",
       "\n",
       "                                            Location             Company_name  \\\n",
       "0             Mumbai, New Delhi, Bangalore/Bengaluru                   Pfizer   \n",
       "1  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...                 Analytos   \n",
       "2              Gurgaon/Gurugram, Bangalore/Bengaluru                Blackbuck   \n",
       "3  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...                 Analytos   \n",
       "4    Gurgaon/Gurugram, United States (USA), Bulgaria                   Adidas   \n",
       "5                                   Gurgaon/Gurugram                   Netomi   \n",
       "6                                              Noida  Gujarat Fluorochemicals   \n",
       "7                                   Gurgaon/Gurugram          Biopeople India   \n",
       "8                                   Gurgaon/Gurugram                   Netomi   \n",
       "9                                              Noida    Profit By Outsourcing   \n",
       "\n",
       "  Experience  \n",
       "0    3-5 Yrs  \n",
       "1    0-2 Yrs  \n",
       "2    3-7 Yrs  \n",
       "3    2-4 Yrs  \n",
       "4    1-6 Yrs  \n",
       "5    3-7 Yrs  \n",
       "6    1-2 Yrs  \n",
       "7    0-2 Yrs  \n",
       "8    3-6 Yrs  \n",
       "9    2-7 Yrs  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Title':job_title, 'Location':job_location, 'Company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c9346e",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data asusual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page asusual\n",
    "6. Repeat this until you get data for 100sunglasses.\n",
    "Note: That all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84f3b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = uc.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce6b3ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "server.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70199f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i had to close a \"Make an account\" request\n",
    "close = server.find_element(By.XPATH, '/html/body/div[2]/div/div/button')\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cabd81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = server.find_element(By.XPATH, '/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "search.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "637ecbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "button = server.find_element(By.CLASS_NAME, 'L0Z3Pu')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f54722fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []\n",
    "prod_descr = []\n",
    "price = []\n",
    "discount = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37cc71fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tags = server.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags:\n",
    "    brands = i.text\n",
    "    brand.append(brands)\n",
    "# here I had to search elements one by one because one of them had another class name. \n",
    "prod_descr_tags = server.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')+server.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\"]')\n",
    "for i in prod_descr_tags:\n",
    "    description = i.text\n",
    "    prod_descr.append(description)\n",
    "    \n",
    "price_tags = server.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags:\n",
    "    prices = i.text\n",
    "    price.append(prices)\n",
    "    \n",
    "discount_tags = server.find_elements(By.XPATH, '//div[@class=\"_3I9_wc\"]')\n",
    "for i in discount_tags:\n",
    "    discounts = i.text\n",
    "    discount.append(discounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9774c07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40 40\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(prod_descr),len(price),len(discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3d4afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here i had to figure it out because the term \"elements\" suggests more than one.\n",
    "\n",
    "next_b = server.find_element(By.XPATH, '//a[@class=\"_1LKTO3\"]')\n",
    "next_b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87069c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tags = server.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags:\n",
    "    brands = i.text\n",
    "    brand.append(brands)\n",
    "\n",
    "prod_descr_tags = server.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')+server.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\"]')\n",
    "for i in prod_descr_tags:\n",
    "    description = i.text\n",
    "    prod_descr.append(description)\n",
    "    \n",
    "price_tags = server.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags:\n",
    "    prices = i.text\n",
    "    price.append(prices)\n",
    "    \n",
    "discount_tags = server.find_elements(By.XPATH, '//div[@class=\"_3I9_wc\"]')\n",
    "for i in discount_tags:\n",
    "    discounts = i.text\n",
    "    discount.append(discounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e97f7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 80 80 80\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(prod_descr),len(price),len(discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ddc1573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here the previous and next button have the same xpath so i had to copy the full xpath\n",
    "next_b = server.find_element(By.XPATH, '/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]')\n",
    "next_b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63039c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_tags = server.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags[0:20]:\n",
    "    brands = i.text\n",
    "    brand.append(brands)\n",
    "\n",
    "prod_descr_tags = server.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')+server.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\"]')\n",
    "for i in prod_descr_tags[0:20]:\n",
    "    description = i.text\n",
    "    prod_descr.append(description)\n",
    "    \n",
    "price_tags = server.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags[0:20]:\n",
    "    prices = i.text\n",
    "    price.append(prices)\n",
    "    \n",
    "discount_tags = server.find_elements(By.XPATH, '//div[@class=\"_3I9_wc\"]')\n",
    "for i in discount_tags[0:20]:\n",
    "    discounts = i.text\n",
    "    discount.append(discounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f1f3764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(prod_descr),len(price),len(discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36779b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Retro Squ...</td>\n",
       "      <td>₹849</td>\n",
       "      <td>₹1,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (59)</td>\n",
       "      <td>₹509</td>\n",
       "      <td>₹1,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (54)</td>\n",
       "      <td>₹224</td>\n",
       "      <td>₹1,599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹268</td>\n",
       "      <td>₹1,599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TamTam</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹181</td>\n",
       "      <td>₹999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Polarized, UV Protection Rectangular Sunglasse...</td>\n",
       "      <td>₹699</td>\n",
       "      <td>₹2,555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹249</td>\n",
       "      <td>₹699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>CRYSTAL CART</td>\n",
       "      <td>Polarized, Gradient, UV Protection, Mirrored O...</td>\n",
       "      <td>₹220</td>\n",
       "      <td>₹1,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>₹1,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Sports Sunglasses (69)</td>\n",
       "      <td>₹345</td>\n",
       "      <td>₹1,245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Name                                Product Description Price  \\\n",
       "0    VINCENT CHASE  by Lenskart Polarized, UV Protection Retro Squ...  ₹849   \n",
       "1    VINCENT CHASE             UV Protection Wayfarer Sunglasses (59)  ₹509   \n",
       "2           PIRASO           UV Protection Clubmaster Sunglasses (54)  ₹224   \n",
       "3           PIRASO       UV Protection Aviator Sunglasses (Free Size)  ₹268   \n",
       "4           TamTam  UV Protection Retro Square Sunglasses (Free Size)  ₹181   \n",
       "..             ...                                                ...   ...   \n",
       "95  ROZZETTA CRAFT  Polarized, UV Protection Rectangular Sunglasse...  ₹699   \n",
       "96      LIZA ANGEL   UV Protection Rectangular Sunglasses (Free Size)  ₹249   \n",
       "97    CRYSTAL CART  Polarized, Gradient, UV Protection, Mirrored O...  ₹220   \n",
       "98       ROYAL SON   Polarized, UV Protection Aviator Sunglasses (58)  ₹599   \n",
       "99           NuVew               UV Protection Sports Sunglasses (69)  ₹345   \n",
       "\n",
       "   Discount  \n",
       "0    ₹1,999  \n",
       "1    ₹1,999  \n",
       "2    ₹1,599  \n",
       "3    ₹1,599  \n",
       "4      ₹999  \n",
       "..      ...  \n",
       "95   ₹2,555  \n",
       "96     ₹699  \n",
       "97   ₹1,999  \n",
       "98   ₹1,999  \n",
       "99   ₹1,245  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Brand Name':brand,'Product Description':prod_descr,'Price':price,'Discount':discount})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81556938",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/productreviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0185b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = uc.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65ceec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the link given wasnt woring. \n",
    "url.get('https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8522469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []\n",
    "summ = []\n",
    "full = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "042b146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_tags = url.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in rating_tags:\n",
    "    rat = i.text\n",
    "    rating.append(rat)\n",
    "    \n",
    "summ_tags = url.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summ_tags:\n",
    "    summary = i.text\n",
    "    summ.append(summary)\n",
    "    \n",
    "full_tags = url.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]')\n",
    "for i in full_tags:\n",
    "    ful = i.text\n",
    "    full.append(ful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd8eedf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(rating),len(summ),len(full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bc4e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_b = url.find_element(By.XPATH, '/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]')\n",
    "next_b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "175a5e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20\n"
     ]
    }
   ],
   "source": [
    "rating_tags = url.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in rating_tags:\n",
    "    rat = i.text\n",
    "    rating.append(rat)\n",
    "    \n",
    "summ_tags = url.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summ_tags:\n",
    "    summary = i.text\n",
    "    summ.append(summary)\n",
    "    \n",
    "full_tags = url.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]')\n",
    "for i in full_tags:\n",
    "    ful = i.text\n",
    "    full.append(ful)\n",
    "\n",
    "print(len(rating),len(summ),len(full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb667cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_b = url.find_element(By.XPATH, '/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]')\n",
    "next_b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "679fe860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30\n"
     ]
    }
   ],
   "source": [
    "rating_tags = url.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in rating_tags:\n",
    "    rat = i.text\n",
    "    rating.append(rat)\n",
    "    \n",
    "summ_tags = url.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summ_tags:\n",
    "    summary = i.text\n",
    "    summ.append(summary)\n",
    "    \n",
    "full_tags = url.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]')\n",
    "for i in full_tags:\n",
    "    ful = i.text\n",
    "    full.append(ful)\n",
    "\n",
    "print(len(rating),len(summ),len(full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e49e20c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_b = url.find_element(By.XPATH, '/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]')\n",
    "next_b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e770c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "# I had to add an extra url.find for bad review wich have a different class\n",
    "rating_tags = url.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')+url.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1rdVr6 _1BLPMq\"]')\n",
    "for i in rating_tags:\n",
    "    rat = i.text\n",
    "    rating.append(rat)\n",
    "    \n",
    "summ_tags = url.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summ_tags:\n",
    "    summary = i.text\n",
    "    summ.append(summary)\n",
    "    \n",
    "full_tags = url.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]')\n",
    "for i in full_tags:\n",
    "    ful = i.text\n",
    "    full.append(ful)\n",
    "\n",
    "print(len(rating),len(summ),len(full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b55a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_b = url.find_element(By.XPATH, '/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]')\n",
    "next_b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f7a745a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50\n"
     ]
    }
   ],
   "source": [
    "rating_tags = url.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in rating_tags:\n",
    "    rat = i.text\n",
    "    rating.append(rat)\n",
    "    \n",
    "summ_tags = url.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summ_tags:\n",
    "    summary = i.text\n",
    "    summ.append(summary)\n",
    "    \n",
    "full_tags = url.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]')\n",
    "for i in full_tags:\n",
    "    ful = i.text\n",
    "    full.append(ful)\n",
    "\n",
    "print(len(rating),len(summ),len(full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa6b85fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_b = url.find_element(By.XPATH, '/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]')\n",
    "next_b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb052d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 60 60\n"
     ]
    }
   ],
   "source": [
    "rating_tags = url.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')+url.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1rdVr6 _1BLPMq\"]')\n",
    "for i in rating_tags:\n",
    "    rat = i.text\n",
    "    rating.append(rat)\n",
    "    \n",
    "summ_tags = url.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summ_tags:\n",
    "    summary = i.text\n",
    "    summ.append(summary)\n",
    "    \n",
    "full_tags = url.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]')\n",
    "for i in full_tags:\n",
    "    ful = i.text\n",
    "    full.append(ful)\n",
    "\n",
    "print(len(rating),len(summ),len(full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe2f24b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_b = url.find_element(By.XPATH, '/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]')\n",
    "next_b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d42baea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 70 70\n"
     ]
    }
   ],
   "source": [
    "rating_tags = url.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')+url.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1rdVr6 _1BLPMq\"]')\n",
    "for i in rating_tags:\n",
    "    rat = i.text\n",
    "    rating.append(rat)\n",
    "    \n",
    "summ_tags = url.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summ_tags:\n",
    "    summary = i.text\n",
    "    summ.append(summary)\n",
    "    \n",
    "full_tags = url.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]')\n",
    "for i in full_tags:\n",
    "    ful = i.text\n",
    "    full.append(ful)\n",
    "\n",
    "print(len(rating),len(summ),len(full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0eba3657",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_b = url.find_element(By.XPATH, '/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]')\n",
    "next_b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "853838ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 80 80\n"
     ]
    }
   ],
   "source": [
    "rating_tags = url.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in rating_tags:\n",
    "    rat = i.text\n",
    "    rating.append(rat)\n",
    "    \n",
    "summ_tags = url.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summ_tags:\n",
    "    summary = i.text\n",
    "    summ.append(summary)\n",
    "    \n",
    "full_tags = url.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]')\n",
    "for i in full_tags:\n",
    "    ful = i.text\n",
    "    full.append(ful)\n",
    "\n",
    "print(len(rating),len(summ),len(full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78c50053",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_b = url.find_element(By.XPATH, '/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]')\n",
    "next_b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99a2682b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 90 90\n"
     ]
    }
   ],
   "source": [
    "rating_tags = url.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in rating_tags:\n",
    "    rat = i.text\n",
    "    rating.append(rat)\n",
    "    \n",
    "summ_tags = url.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summ_tags:\n",
    "    summary = i.text\n",
    "    summ.append(summary)\n",
    "    \n",
    "full_tags = url.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]')\n",
    "for i in full_tags:\n",
    "    ful = i.text\n",
    "    full.append(ful)\n",
    "\n",
    "print(len(rating),len(summ),len(full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ee7db99",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_b = url.find_element(By.XPATH, '/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]')\n",
    "next_b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a1771f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "rating_tags = url.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in rating_tags:\n",
    "    rat = i.text\n",
    "    rating.append(rat)\n",
    "    \n",
    "summ_tags = url.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summ_tags:\n",
    "    summary = i.text\n",
    "    summ.append(summary)\n",
    "    \n",
    "full_tags = url.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]')\n",
    "for i in full_tags:\n",
    "    ful = i.text\n",
    "    full.append(ful)\n",
    "\n",
    "print(len(rating),len(summ),len(full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07693c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Summary review</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>I'm switching this phone to oppo reno 10x zoom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Its good.. a little heavy on my pinky but its ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Simply Awesome\\n\\nI have upgraded from iPhone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Damn this phone is a blast . Upgraded from and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Worth the money’ starting first from its perfo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating        Summary review  \\\n",
       "0       5        Simply awesome   \n",
       "1       5      Perfect product!   \n",
       "2       5   Best in the market!   \n",
       "3       4       Value-for-money   \n",
       "4       5    Highly recommended   \n",
       "..    ...                   ...   \n",
       "95      4  Good quality product   \n",
       "96      5             Wonderful   \n",
       "97      5              Terrific   \n",
       "98      5   Best in the market!   \n",
       "99      5      Perfect product!   \n",
       "\n",
       "                                          Full review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   I'm Really happy with the product\\nDelivery wa...  \n",
       "4   It's my first time to use iOS phone and I am l...  \n",
       "..                                                ...  \n",
       "95  I'm switching this phone to oppo reno 10x zoom...  \n",
       "96  Its good.. a little heavy on my pinky but its ...  \n",
       "97  Simply Awesome\\n\\nI have upgraded from iPhone ...  \n",
       "98  Damn this phone is a blast . Upgraded from and...  \n",
       "99  Worth the money’ starting first from its perfo...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Rating':rating,'Summary review':summ,'Full review':full})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca60bda4",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eeab765",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa5cd81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "server.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b5bbac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "close = server.find_element(By.XPATH, '/html/body/div[2]/div/div/button')\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ed10bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = server.find_element(By.XPATH, '/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "search.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8f60709",
   "metadata": {},
   "outputs": [],
   "source": [
    "button = server.find_element(By.XPATH, '//button[@class=\"L0Z3Pu\"]')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "750b6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []\n",
    "descr = []\n",
    "price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ccb0214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "brand_tags = server.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags:\n",
    "    brands = i.text\n",
    "    brand.append(brands)\n",
    "\n",
    "descr_tags = server.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')+server.find_elements(By.XPATH, '//a[@class=\"IRpwTa _2-ICcC\"]')\n",
    "for i in descr_tags:\n",
    "    description = i.text\n",
    "    descr.append(description)\n",
    "    \n",
    "price_tags = server.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags:\n",
    "    prices = i.text\n",
    "    price.append(prices)\n",
    "    \n",
    "print(len(brand), len(descr), len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b50f1b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_b = server.find_element(By.XPATH, '/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "next_b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20e6912a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 80 80\n"
     ]
    }
   ],
   "source": [
    "brand_tags = server.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags:\n",
    "    brands = i.text\n",
    "    brand.append(brands)\n",
    "\n",
    "descr_tags = server.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')+server.find_elements(By.XPATH, '//a[@class=\"IRpwTa _2-ICcC\"]')\n",
    "for i in descr_tags:\n",
    "    description = i.text\n",
    "    descr.append(description)\n",
    "    \n",
    "price_tags = server.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags:\n",
    "    prices = i.text\n",
    "    price.append(prices)\n",
    "    \n",
    "print(len(brand), len(descr), len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b10d611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_b = server.find_element(By.XPATH, '/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "next_b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2be0a614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "brand_tags = server.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags[0:20]:\n",
    "    brands = i.text\n",
    "    brand.append(brands)\n",
    "\n",
    "descr_tags = server.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')+server.find_elements(By.XPATH, '//a[@class=\"IRpwTa _2-ICcC\"]')\n",
    "for i in descr_tags[0:20]:\n",
    "    description = i.text\n",
    "    descr.append(description)\n",
    "    \n",
    "price_tags = server.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags[0:20]:\n",
    "    prices = i.text\n",
    "    price.append(prices)\n",
    "    \n",
    "print(len(brand), len(descr), len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d525054f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brands</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Synthetic| Lightweight| Premiun| Comfort| Summ...</td>\n",
       "      <td>₹269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Premium Sports Shoes For Men Pack Of 2 Sneaker...</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>bacca bucci</td>\n",
       "      <td>Comfy Mid-Top Casual Chunky Streetwear Fashion...</td>\n",
       "      <td>₹1,599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Asics</td>\n",
       "      <td>PRIME JOGGER LS Sneakers For Men</td>\n",
       "      <td>₹1,732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>LIBERTY</td>\n",
       "      <td>JUMP-02 Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brands                                        Description   Price\n",
       "0        Labbin                                   Sneakers For Men    ₹379\n",
       "1      RapidBox                                   Sneakers For Men    ₹579\n",
       "2          aadi  Synthetic| Lightweight| Premiun| Comfort| Summ...    ₹269\n",
       "3         BIRDE  Premium Sports Shoes For Men Pack Of 2 Sneaker...    ₹449\n",
       "4         BIRDE      Combo Pack Of 2 Casual Shoes Sneakers For Men    ₹449\n",
       "..          ...                                                ...     ...\n",
       "95  bacca bucci  Comfy Mid-Top Casual Chunky Streetwear Fashion...  ₹1,599\n",
       "96       BRUTON      Combo Pack Of 2 Casual Shoes Sneakers For Men    ₹449\n",
       "97        Asics                   PRIME JOGGER LS Sneakers For Men  ₹1,732\n",
       "98      LIBERTY                           JUMP-02 Sneakers For Men    ₹449\n",
       "99   HIGHLANDER                                   Sneakers For Men    ₹696\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Brands':brand,'Description':descr,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9b451d",
   "metadata": {},
   "source": [
    "Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then\n",
    "set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a88a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9413ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon.get('https://www.amazon.co.uk/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95ca0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = amazon.find_element(By.XPATH, '/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "search.send_keys('laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af5b821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "button = amazon.find_element(By.XPATH, '/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ec43584",
   "metadata": {},
   "outputs": [],
   "source": [
    "cookie = amazon.find_element(By.XPATH, '//input[@class=\"a-button-input celwidget\"]')\n",
    "cookie.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75d6ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_ = amazon.find_element(By.XPATH, '/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[7]/ul[5]/span[20]/li/span/a/div/label/i')\n",
    "filter_.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "086f8da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "rating = []\n",
    "price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e50e2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "title_tags = amazon.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    titles = i.text\n",
    "    title.append(titles)\n",
    "    \n",
    "rating_tags = amazon.find_elements(By.XPATH, '//i[@class=\"a-icon a-icon-star-small a-star-small-4-5 aok-align-bottom\"]')\n",
    "for i in rating_tags[0:10]:\n",
    "    ratings = i.text\n",
    "    rating.append(ratings)\n",
    "    \n",
    "price_tags = amazon.find_elements(By.XPATH, '//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tags[0:10]:\n",
    "    prices = i.text\n",
    "    price.append(prices)\n",
    "    \n",
    "print(len(title),len(rating),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbc61791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS ZenBook Flip S13 UX371EA 13.3-inch 4K Tou...</td>\n",
       "      <td></td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS ZenBook Flip OLED UX363EA 13.3 Intel EVO ...</td>\n",
       "      <td></td>\n",
       "      <td>899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSI Katana GF76 Gaming Laptop (12UB-027UK), 12...</td>\n",
       "      <td></td>\n",
       "      <td>1,259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell Latitude 5430 14.0 inch FHD Business Lapt...</td>\n",
       "      <td></td>\n",
       "      <td>1,078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS ExpertBook B9 B9400CEA 14.0” Full HD Lapt...</td>\n",
       "      <td></td>\n",
       "      <td>1,645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Acer Aspire 3 A315-58 15.6 Inch Laptop - (Inte...</td>\n",
       "      <td></td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dell Latitude 7480 14\" Full HD Core i7-6600U 1...</td>\n",
       "      <td></td>\n",
       "      <td>899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo IdeaPad 3 15ITL6 15.6 FHD Cloudbook Lap...</td>\n",
       "      <td></td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo Ideapad 3 15ITL6 15.6 Inch FHD Cloudboo...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Elitebook 840 G3 Laptop Intel i7-6600U 2.6G...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Rating  Price\n",
       "0  ASUS ZenBook Flip S13 UX371EA 13.3-inch 4K Tou...           999\n",
       "1  ASUS ZenBook Flip OLED UX363EA 13.3 Intel EVO ...           899\n",
       "2  MSI Katana GF76 Gaming Laptop (12UB-027UK), 12...         1,259\n",
       "3  Dell Latitude 5430 14.0 inch FHD Business Lapt...         1,078\n",
       "4  ASUS ExpertBook B9 B9400CEA 14.0” Full HD Lapt...         1,645\n",
       "5  Acer Aspire 3 A315-58 15.6 Inch Laptop - (Inte...           999\n",
       "6  Dell Latitude 7480 14\" Full HD Core i7-6600U 1...           899\n",
       "7  Lenovo IdeaPad 3 15ITL6 15.6 FHD Cloudbook Lap...           790\n",
       "8  Lenovo Ideapad 3 15ITL6 15.6 Inch FHD Cloudboo...              \n",
       "9  HP Elitebook 840 G3 Laptop Intel i7-6600U 2.6G...              "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Title':title,'Rating':rating,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e3cc9",
   "metadata": {},
   "source": [
    "Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on TopQuotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb68ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a641671",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.get('https://www.azquotes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b3a04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = q.find_element(By.XPATH, '/html/body/div[1]/div[2]/div[1]/div/div[3]/ul/li[5]/a')\n",
    "top.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f49d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote = []\n",
    "author = []\n",
    "type_of = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83304ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "quote_tags = q.find_elements(By.XPATH, '//a[@class=\"title\"]')\n",
    "for i in quote_tags:\n",
    "    quotes = i.text\n",
    "    quote.append(quotes)\n",
    "    \n",
    "author_tags = q.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags:\n",
    "    authors = i.text\n",
    "    author.append(authors)\n",
    "    \n",
    "type_of_tags = q.find_elements(By.XPATH, '//div[@class=\"tags\"]')\n",
    "for i in type_of_tags:\n",
    "    type_ = i.text\n",
    "    type_of.append(type_)\n",
    "    \n",
    "print(len(quote),len(author),len(type_of))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc10c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_ = q.find_element(By.XPATH, '/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[3]/a')\n",
    "next_.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "509cb3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200 200\n"
     ]
    }
   ],
   "source": [
    "quote_tags = q.find_elements(By.XPATH, '//a[@class=\"title\"]')\n",
    "for i in quote_tags:\n",
    "    quotes = i.text\n",
    "    quote.append(quotes)\n",
    "    \n",
    "author_tags = q.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags:\n",
    "    authors = i.text\n",
    "    author.append(authors)\n",
    "    \n",
    "type_of_tags = q.find_elements(By.XPATH, '//div[@class=\"tags\"]')\n",
    "for i in type_of_tags:\n",
    "    type_ = i.text\n",
    "    type_of.append(type_)\n",
    "    \n",
    "print(len(quote),len(author),len(type_of))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9be35eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_ = q.find_element(By.XPATH, '/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[5]/a')\n",
    "next_.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f84107b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 300 300\n"
     ]
    }
   ],
   "source": [
    "quote_tags = q.find_elements(By.XPATH, '//a[@class=\"title\"]')\n",
    "for i in quote_tags:\n",
    "    quotes = i.text\n",
    "    quote.append(quotes)\n",
    "    \n",
    "author_tags = q.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags:\n",
    "    authors = i.text\n",
    "    author.append(authors)\n",
    "    \n",
    "type_of_tags = q.find_elements(By.XPATH, '//div[@class=\"tags\"]')\n",
    "for i in type_of_tags:\n",
    "    type_ = i.text\n",
    "    type_of.append(type_)\n",
    "    \n",
    "print(len(quote),len(author),len(type_of))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5ae6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_ = q.find_element(By.XPATH, '/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[6]/a')\n",
    "next_.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39f5db95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 400 400\n"
     ]
    }
   ],
   "source": [
    "quote_tags = q.find_elements(By.XPATH, '//a[@class=\"title\"]')\n",
    "for i in quote_tags:\n",
    "    quotes = i.text\n",
    "    quote.append(quotes)\n",
    "    \n",
    "author_tags = q.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags:\n",
    "    authors = i.text\n",
    "    author.append(authors)\n",
    "    \n",
    "type_of_tags = q.find_elements(By.XPATH, '//div[@class=\"tags\"]')\n",
    "for i in type_of_tags:\n",
    "    type_ = i.text\n",
    "    type_of.append(type_)\n",
    "    \n",
    "print(len(quote),len(author),len(type_of))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dce90f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_ = q.find_element(By.XPATH, '/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[7]/a')\n",
    "next_.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0e43518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 500 500\n"
     ]
    }
   ],
   "source": [
    "quote_tags = q.find_elements(By.XPATH, '//a[@class=\"title\"]')\n",
    "for i in quote_tags:\n",
    "    quotes = i.text\n",
    "    quote.append(quotes)\n",
    "    \n",
    "author_tags = q.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags:\n",
    "    authors = i.text\n",
    "    author.append(authors)\n",
    "    \n",
    "type_of_tags = q.find_elements(By.XPATH, '//div[@class=\"tags\"]')\n",
    "for i in type_of_tags:\n",
    "    type_ = i.text\n",
    "    type_of.append(type_)\n",
    "    \n",
    "print(len(quote),len(author),len(type_of))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29385a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_ = q.find_element(By.XPATH, '/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[8]/a')\n",
    "next_.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e04bb375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 600 600\n"
     ]
    }
   ],
   "source": [
    "quote_tags = q.find_elements(By.XPATH, '//a[@class=\"title\"]')\n",
    "for i in quote_tags:\n",
    "    quotes = i.text\n",
    "    quote.append(quotes)\n",
    "    \n",
    "author_tags = q.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags:\n",
    "    authors = i.text\n",
    "    author.append(authors)\n",
    "    \n",
    "type_of_tags = q.find_elements(By.XPATH, '//div[@class=\"tags\"]')\n",
    "for i in type_of_tags:\n",
    "    type_ = i.text\n",
    "    type_of.append(type_)\n",
    "    \n",
    "print(len(quote),len(author),len(type_of))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b99e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_ = q.find_element(By.XPATH, '/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[9]/a')\n",
    "next_.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d41c7391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 700 700\n"
     ]
    }
   ],
   "source": [
    "quote_tags = q.find_elements(By.XPATH, '//a[@class=\"title\"]')\n",
    "for i in quote_tags:\n",
    "    quotes = i.text\n",
    "    quote.append(quotes)\n",
    "    \n",
    "author_tags = q.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags:\n",
    "    authors = i.text\n",
    "    author.append(authors)\n",
    "    \n",
    "type_of_tags = q.find_elements(By.XPATH, '//div[@class=\"tags\"]')\n",
    "for i in type_of_tags:\n",
    "    type_ = i.text\n",
    "    type_of.append(type_)\n",
    "    \n",
    "print(len(quote),len(author),len(type_of))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf0c578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_ = q.find_element(By.XPATH, '/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[10]/a')\n",
    "next_.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f983efbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 800 800\n"
     ]
    }
   ],
   "source": [
    "quote_tags = q.find_elements(By.XPATH, '//a[@class=\"title\"]')\n",
    "for i in quote_tags:\n",
    "    quotes = i.text\n",
    "    quote.append(quotes)\n",
    "    \n",
    "author_tags = q.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags:\n",
    "    authors = i.text\n",
    "    author.append(authors)\n",
    "    \n",
    "type_of_tags = q.find_elements(By.XPATH, '//div[@class=\"tags\"]')\n",
    "for i in type_of_tags:\n",
    "    type_ = i.text\n",
    "    type_of.append(type_)\n",
    "    \n",
    "print(len(quote),len(author),len(type_of))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc317008",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_ = q.find_element(By.XPATH, '/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[11]/a')\n",
    "next_.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7a51ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 900 900\n"
     ]
    }
   ],
   "source": [
    "quote_tags = q.find_elements(By.XPATH, '//a[@class=\"title\"]')\n",
    "for i in quote_tags:\n",
    "    quotes = i.text\n",
    "    quote.append(quotes)\n",
    "    \n",
    "author_tags = q.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags:\n",
    "    authors = i.text\n",
    "    author.append(authors)\n",
    "    \n",
    "type_of_tags = q.find_elements(By.XPATH, '//div[@class=\"tags\"]')\n",
    "for i in type_of_tags:\n",
    "    type_ = i.text\n",
    "    type_of.append(type_)\n",
    "    \n",
    "print(len(quote),len(author),len(type_of))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d9da1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_ = q.find_element(By.XPATH, '/html/body/div[1]/div[3]/div/div/div/div[1]/div/div[3]/li[12]/a')\n",
    "next_.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "206b874b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "quote_tags = q.find_elements(By.XPATH, '//a[@class=\"title\"]')\n",
    "for i in quote_tags:\n",
    "    quotes = i.text\n",
    "    quote.append(quotes)\n",
    "    \n",
    "author_tags = q.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags:\n",
    "    authors = i.text\n",
    "    author.append(authors)\n",
    "    \n",
    "type_of_tags = q.find_elements(By.XPATH, '//div[@class=\"tags\"]')\n",
    "for i in type_of_tags:\n",
    "    type_ = i.text\n",
    "    type_of.append(type_)\n",
    "    \n",
    "print(len(quote),len(author),len(type_of))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "180380ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Quote              Author  \\\n",
       "0  The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1  One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2  Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3  Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4  You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "\n",
       "                                       Type  \n",
       "0  Essence, Deep Thought, Transcendentalism  \n",
       "1                 Inspiration, Past, Trying  \n",
       "2                       Country, Peace, War  \n",
       "3        Inspirational, Motivational, Death  \n",
       "4              4th Of July, Food, Patriotic  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Quote':quote,'Author':author,'Type':type_of})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529ff010",
   "metadata": {},
   "source": [
    "Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead,\n",
    "Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b095ca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f710c0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url.get('https://www.jagranjosh.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a82c74d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "click = url.find_element(By.XPATH, '/html/body/div/div[1]/div/div[1]/div/div[5]/div/div[1]/header/div[3]/ul/li[3]/a')\n",
    "click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b196d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "prime = url.find_element(By.XPATH, '/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a')\n",
    "prime.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3af6bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "born_dead = []\n",
    "term = []\n",
    "remarks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4effc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[2]/td[2]/p/strong/a')\n",
    "for i in name_tags:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "born_dead_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[2]/td[3]/p')\n",
    "for i in born_dead_tags:\n",
    "    born = i.text\n",
    "    born_dead.append(born)\n",
    "    \n",
    "term_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[2]/td[4]')\n",
    "for i in term_tags:\n",
    "    terms = i.text\n",
    "    term.append(terms)\n",
    "    \n",
    "remarks_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[2]/td[5]')\n",
    "for i in remarks_tags:\n",
    "    remark = i.text\n",
    "    remarks.append(remark)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4cd7a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[3]/td[2]')\n",
    "for i in name_tags:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "born_dead_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[3]/td[3]')\n",
    "for i in born_dead_tags:\n",
    "    born = i.text\n",
    "    born_dead.append(born)\n",
    "    \n",
    "term_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[3]/td[4]')\n",
    "for i in term_tags:\n",
    "    terms = i.text\n",
    "    term.append(terms)\n",
    "    \n",
    "remarks_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[3]/td[5]')\n",
    "for i in remarks_tags:\n",
    "    remark = i.text\n",
    "    remarks.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e46ac44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[4]/td[2]')\n",
    "for i in name_tags:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "born_dead_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[4]/td[3]')\n",
    "for i in born_dead_tags:\n",
    "    born = i.text\n",
    "    born_dead.append(born)\n",
    "    \n",
    "term_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[4]/td[4]')\n",
    "for i in term_tags:\n",
    "    terms = i.text\n",
    "    term.append(terms)\n",
    "    \n",
    "remarks_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[4]/td[5]')\n",
    "for i in remarks_tags:\n",
    "    remark = i.text\n",
    "    remarks.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91940533",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[5]/td[2]')\n",
    "for i in name_tags:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "born_dead_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[5]/td[3]')\n",
    "for i in born_dead_tags:\n",
    "    born = i.text\n",
    "    born_dead.append(born)\n",
    "    \n",
    "term_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[5]/td[4]')\n",
    "for i in term_tags:\n",
    "    terms = i.text\n",
    "    term.append(terms)\n",
    "    \n",
    "remarks_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[5]/td[5]')\n",
    "for i in remarks_tags:\n",
    "    remark = i.text\n",
    "    remarks.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "24a1e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[6]/td[2]/p/strong/a')\n",
    "for i in name_tags:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "born_dead_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[6]/td[3]')\n",
    "for i in born_dead_tags:\n",
    "    born = i.text\n",
    "    born_dead.append(born)\n",
    "    \n",
    "term_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[6]/td[4]')\n",
    "for i in term_tags:\n",
    "    terms = i.text\n",
    "    term.append(terms)\n",
    "    \n",
    "remarks_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[6]/td[5]')\n",
    "for i in remarks_tags:\n",
    "    remark = i.text\n",
    "    remarks.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "980af3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[7]/td[2]')\n",
    "for i in name_tags:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "born_dead_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[7]/td[3]')\n",
    "for i in born_dead_tags:\n",
    "    born = i.text\n",
    "    born_dead.append(born)\n",
    "    \n",
    "term_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[7]/td[4]')\n",
    "for i in term_tags:\n",
    "    terms = i.text\n",
    "    term.append(terms)\n",
    "    \n",
    "remarks_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[7]/td[5]')\n",
    "for i in remarks_tags:\n",
    "    remark = i.text\n",
    "    remarks.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4349362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[8]/td[2]')\n",
    "for i in name_tags:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "born_dead_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[8]/td[3]')\n",
    "for i in born_dead_tags:\n",
    "    born = i.text\n",
    "    born_dead.append(born)\n",
    "    \n",
    "term_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[8]/td[4]')\n",
    "for i in term_tags:\n",
    "    terms = i.text\n",
    "    term.append(terms)\n",
    "    \n",
    "remarks_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[8]/td[5]')\n",
    "for i in remarks_tags:\n",
    "    remark = i.text\n",
    "    remarks.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c4c4719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[9]/td[2]/p/strong/a')\n",
    "for i in name_tags:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "born_dead_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[9]/td[3]')\n",
    "for i in born_dead_tags:\n",
    "    born = i.text\n",
    "    born_dead.append(born)\n",
    "    \n",
    "term_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[9]/td[4]')\n",
    "for i in term_tags:\n",
    "    terms = i.text\n",
    "    term.append(terms)\n",
    "    \n",
    "remarks_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[9]/td[5]')\n",
    "for i in remarks_tags:\n",
    "    remark = i.text\n",
    "    remarks.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae512a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[10]/td[2]/p/a')\n",
    "for i in name_tags:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "born_dead_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[10]/td[3]')\n",
    "for i in born_dead_tags:\n",
    "    born = i.text\n",
    "    born_dead.append(born)\n",
    "    \n",
    "term_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[10]/td[4]')\n",
    "for i in term_tags:\n",
    "    terms = i.text\n",
    "    term.append(terms)\n",
    "    \n",
    "remarks_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[10]/td[5]')\n",
    "for i in remarks_tags:\n",
    "    remark = i.text\n",
    "    remarks.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "20513b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[11]/td[2]')\n",
    "for i in name_tags:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "born_dead_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[11]/td[3]')\n",
    "for i in born_dead_tags:\n",
    "    born = i.text\n",
    "    born_dead.append(born)\n",
    "    \n",
    "term_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[11]/td[4]')\n",
    "for i in term_tags:\n",
    "    terms = i.text\n",
    "    term.append(terms)\n",
    "    \n",
    "remarks_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[11]/td[5]')\n",
    "for i in remarks_tags:\n",
    "    remark = i.text\n",
    "    remarks.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c54ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[12]/td[2]/p/strong/a')\n",
    "for i in name_tags:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "born_dead_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[12]/td[3]')\n",
    "for i in born_dead_tags:\n",
    "    born = i.text\n",
    "    born_dead.append(born)\n",
    "    \n",
    "term_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[12]/td[4]')\n",
    "for i in term_tags:\n",
    "    terms = i.text\n",
    "    term.append(terms)\n",
    "    \n",
    "remarks_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[12]/td[5]')\n",
    "for i in remarks_tags:\n",
    "    remark = i.text\n",
    "    remarks.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2604407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[13]/td[2]')\n",
    "for i in name_tags:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "born_dead_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[13]/td[3]')\n",
    "for i in born_dead_tags:\n",
    "    born = i.text\n",
    "    born_dead.append(born)\n",
    "    \n",
    "term_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[13]/td[4]')\n",
    "for i in term_tags:\n",
    "    terms = i.text\n",
    "    term.append(terms)\n",
    "    \n",
    "remarks_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[13]/td[5]')\n",
    "for i in remarks_tags:\n",
    "    remark = i.text\n",
    "    remarks.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a0da9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[14]/td[2]/p/strong/a')\n",
    "for i in name_tags:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "born_dead_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[14]/td[3]')\n",
    "for i in born_dead_tags:\n",
    "    born = i.text\n",
    "    born_dead.append(born)\n",
    "    \n",
    "term_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[14]/td[4]')\n",
    "for i in term_tags:\n",
    "    terms = i.text\n",
    "    term.append(terms)\n",
    "    \n",
    "remarks_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[14]/td[5]')\n",
    "for i in remarks_tags:\n",
    "    remark = i.text\n",
    "    remarks.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f0d52984",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[15]/td[2]')\n",
    "for i in name_tags:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "born_dead_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[15]/td[3]')\n",
    "for i in born_dead_tags:\n",
    "    born = i.text\n",
    "    born_dead.append(born)\n",
    "    \n",
    "term_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[15]/td[4]')\n",
    "for i in term_tags:\n",
    "    terms = i.text\n",
    "    term.append(terms)\n",
    "    \n",
    "remarks_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[15]/td[5]')\n",
    "for i in remarks_tags:\n",
    "    remark = i.text\n",
    "    remarks.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "47b6b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[16]/td[2]')\n",
    "for i in name_tags:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "born_dead_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[16]/td[3]')\n",
    "for i in born_dead_tags:\n",
    "    born = i.text\n",
    "    born_dead.append(born)\n",
    "    \n",
    "term_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[16]/td[4]')\n",
    "for i in term_tags:\n",
    "    terms = i.text\n",
    "    term.append(terms)\n",
    "    \n",
    "remarks_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[16]/td[5]')\n",
    "for i in remarks_tags:\n",
    "    remark = i.text\n",
    "    remarks.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "15541402",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[17]/td[2]/p/a')\n",
    "for i in name_tags:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "born_dead_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[17]/td[3]')\n",
    "for i in born_dead_tags:\n",
    "    born = i.text\n",
    "    born_dead.append(born)\n",
    "    \n",
    "term_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[17]/td[4]')\n",
    "for i in term_tags:\n",
    "    terms = i.text\n",
    "    term.append(terms)\n",
    "    \n",
    "remarks_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[17]/td[5]')\n",
    "for i in remarks_tags:\n",
    "    remark = i.text\n",
    "    remarks.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4556803",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[18]/td[2]/p/strong/a')\n",
    "for i in name_tags:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "born_dead_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[18]/td[3]')\n",
    "for i in born_dead_tags:\n",
    "    born = i.text\n",
    "    born_dead.append(born)\n",
    "    \n",
    "term_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[18]/td[4]')\n",
    "for i in term_tags:\n",
    "    terms = i.text\n",
    "    term.append(terms)\n",
    "    \n",
    "remarks_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[18]/td[5]')\n",
    "for i in remarks_tags:\n",
    "    remark = i.text\n",
    "    remarks.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b8de3dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[19]/td[2]/p/a')\n",
    "for i in name_tags:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "born_dead_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[19]/td[3]')\n",
    "for i in born_dead_tags:\n",
    "    born = i.text\n",
    "    born_dead.append(born)\n",
    "    \n",
    "term_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[19]/td[4]')\n",
    "for i in term_tags:\n",
    "    terms = i.text\n",
    "    term.append(terms)\n",
    "    \n",
    "remarks_tags = url.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[19]/td[5]')\n",
    "for i in remarks_tags:\n",
    "    remark = i.text\n",
    "    remarks.append(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d3a80c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Born/Dead</th>\n",
       "      <th>Terms of office</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889–1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964\\n16 years, 286 days</td>\n",
       "      <td>The first prime minister of India and the longest-serving PM of India, the first to die in office.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>(1904–1966)</td>\n",
       "      <td>9 June 1964 to 11 January 1966\\n1 year, 216 days</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisan' during the Indo-Pak war of 1965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>27 May 1964 to 9 June 1964,\\n13 days</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gulzari Lal Nanda  (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>11 January 1966 to 24 January 1966\\n13 days</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>24 January 1966 to 24 March 1977\\n11 years, 59 days</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>(1896–1995)</td>\n",
       "      <td>24 March 1977 to  28 July 1979 \\n2 year, 126 days</td>\n",
       "      <td>Oldest to become PM (81 years old) and first to resign from office</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>(1902–1987)</td>\n",
       "      <td>28 July 1979 to 14 January 1980\\n170 days</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>14 January 1980 to 31 October 1984\\n4 years, 291 days</td>\n",
       "      <td>The first lady who served as PM for the second term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>(1944–1991)</td>\n",
       "      <td>31 October 1984 to 2 December 1989\\n5 years, 32 days</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>(1931–2008)</td>\n",
       "      <td>2 December 1989 to 10 November 1990\\n343 days</td>\n",
       "      <td>First PM to step down after a vote of no confidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>(1927–2007)</td>\n",
       "      <td>10 November 1990 to 21 June 1991\\n223 days</td>\n",
       "      <td>He belongs to  Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>(1921–2004)</td>\n",
       "      <td>21 June 1991 to 16 May 1996\\n4 years, 330 days</td>\n",
       "      <td>First PM from south India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924- 2018)</td>\n",
       "      <td>16 May 1996 to 1 June 1996\\n16 days</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>(born 1933)</td>\n",
       "      <td>1 June 1996 to 21 April 1997\\n324 days</td>\n",
       "      <td>He belongs to  Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>(1919–2012)</td>\n",
       "      <td>21 April 1997 to 19 March 1998 \\n332 days</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924-2018)</td>\n",
       "      <td>19 March 1998 to 22 May 2004 \\n6 years, 64 days</td>\n",
       "      <td>The first non-congress PM who completed a full term as PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>(born 1932)</td>\n",
       "      <td>22 May 2004 to 26 May 2014   \\n10 years, 4 days</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>26 May 2014 - Present</td>\n",
       "      <td>4th Prime Minister of India who served two consecutive tenures</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name     Born/Dead  \\\n",
       "0             Jawahar Lal Nehru   (1889–1964)   \n",
       "1           Lal Bahadur Shastri   (1904–1966)   \n",
       "2     Gulzarilal Nanda (Acting)   (1898-1998)   \n",
       "3   Gulzari Lal Nanda  (Acting)   (1898-1998)   \n",
       "4                 Indira Gandhi   (1917–1984)   \n",
       "5                 Morarji Desai   (1896–1995)   \n",
       "6                  Charan Singh   (1902–1987)   \n",
       "7                 Indira Gandhi   (1917–1984)   \n",
       "8                  Rajiv Gandhi   (1944–1991)   \n",
       "9                   V. P. Singh   (1931–2008)   \n",
       "10              Chandra Shekhar   (1927–2007)   \n",
       "11          P. V. Narasimha Rao   (1921–2004)   \n",
       "12         Atal Bihari Vajpayee  (1924- 2018)   \n",
       "13             H. D. Deve Gowda   (born 1933)   \n",
       "14           Inder Kumar Gujral   (1919–2012)   \n",
       "15         Atal Bihari Vajpayee   (1924-2018)   \n",
       "16               Manmohan Singh   (born 1932)   \n",
       "17                Narendra Modi   (born 1950)   \n",
       "\n",
       "                                          Terms of office  \\\n",
       "0       15 August 1947 to 27 May 1964\\n16 years, 286 days   \n",
       "1        9 June 1964 to 11 January 1966\\n1 year, 216 days   \n",
       "2                    27 May 1964 to 9 June 1964,\\n13 days   \n",
       "3             11 January 1966 to 24 January 1966\\n13 days   \n",
       "4     24 January 1966 to 24 March 1977\\n11 years, 59 days   \n",
       "5       24 March 1977 to  28 July 1979 \\n2 year, 126 days   \n",
       "6               28 July 1979 to 14 January 1980\\n170 days   \n",
       "7   14 January 1980 to 31 October 1984\\n4 years, 291 days   \n",
       "8    31 October 1984 to 2 December 1989\\n5 years, 32 days   \n",
       "9           2 December 1989 to 10 November 1990\\n343 days   \n",
       "10             10 November 1990 to 21 June 1991\\n223 days   \n",
       "11         21 June 1991 to 16 May 1996\\n4 years, 330 days   \n",
       "12                    16 May 1996 to 1 June 1996\\n16 days   \n",
       "13                 1 June 1996 to 21 April 1997\\n324 days   \n",
       "14              21 April 1997 to 19 March 1998 \\n332 days   \n",
       "15        19 March 1998 to 22 May 2004 \\n6 years, 64 days   \n",
       "16        22 May 2004 to 26 May 2014   \\n10 years, 4 days   \n",
       "17                                  26 May 2014 - Present   \n",
       "\n",
       "                                                                                               Remarks  \n",
       "0   The first prime minister of India and the longest-serving PM of India, the first to die in office.  \n",
       "1                     He has given the slogan of 'Jai Jawan Jai Kisan' during the Indo-Pak war of 1965  \n",
       "2                                                                             First acting PM of India  \n",
       "3                                                                                                    -  \n",
       "4                                                                 First female Prime Minister of India  \n",
       "5                                   Oldest to become PM (81 years old) and first to resign from office  \n",
       "6                                                              Only PM who did not face the Parliament  \n",
       "7                                                  The first lady who served as PM for the second term  \n",
       "8                                                                 Youngest to become PM (40 years old)  \n",
       "9                                                  First PM to step down after a vote of no confidence  \n",
       "10                                                               He belongs to  Samajwadi Janata Party  \n",
       "11                                                                           First PM from south India  \n",
       "12                                                                              PM for shortest tenure  \n",
       "13                                                                           He belongs to  Janata Dal  \n",
       "14                                                                                              ------  \n",
       "15                                           The first non-congress PM who completed a full term as PM  \n",
       "16                                                                                       First Sikh PM  \n",
       "17                                      4th Prime Minister of India who served two consecutive tenures  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Name':name,'Born/Dead':born_dead,'Terms of office':term,'Remarks':remarks})\n",
    "df\n",
    "#i have a feeling that this problem could be solved with a way faster method. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa1bf22",
   "metadata": {},
   "source": [
    "Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e.\n",
    "Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.motor1.com/\n",
    "2. Then You have to click on the List option from Dropdown menu on leftside.\n",
    "3. Then click on 50 most expensive carsin the world..\n",
    "4. Then scrap the mentioned data and make the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c9d3d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf70795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "server.get('https://www.motor1.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9402dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "accept = server.find_element(By.XPATH, '/html/body/div[12]/div[2]/div/div/div[2]/div/div/button')\n",
    "accept.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cc411a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = server.find_element(By.XPATH, '/html/body/div[3]/div[2]/div/div/div[3]/div/div/div/form/input')\n",
    "search.send_keys('50 most expensive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d81b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "button = server.find_element(By.XPATH, '/html/body/div[3]/div[2]/div/div/div[3]/div/div/div/form/button[1]')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dab9b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = server.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div[1]/div/div/div[3]/div/div[1]/h3/a')\n",
    "article.click()\n",
    "\n",
    "# I couldn t find the list mention in task so I chose to search for the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "450fa799",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d43b5fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n"
     ]
    }
   ],
   "source": [
    "name_tags = server.find_elements(By.XPATH, '//h3[@class=\"subheader\"]')\n",
    "for i in name_tags[0:50]:\n",
    "    names = i.text\n",
    "    name.append(names)\n",
    "    \n",
    "price_tags = server.find_elements(By.TAG_NAME,'strong')\n",
    "for i in price_tags[0:50]:\n",
    "    prices = i.text\n",
    "    price.append(prices)\n",
    "    \n",
    "print(len(name), len(price))\n",
    "\n",
    "# I cant find a xpath for all the prices so I should copy the xpath for each price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de4a92d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>De Tomaso P72</td>\n",
       "      <td>Price: $1.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ferrari LaFerrari</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pagani Huayra</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>McLaren Elva</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zenvo TSR-S</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "      <td>Price: $1.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lotus Evija</td>\n",
       "      <td>Price: $2.0 Million*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "      <td>Price: $2.1 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Delage D12</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "      <td>Price: $2.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ferrari FXX K Evo</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "      <td>Price: $2.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "      <td>Price: $3.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>McLaren Solus</td>\n",
       "      <td>Price: $3.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Pagani Huayra Roadster BC</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bugatti Chiron Pur Sport</td>\n",
       "      <td>Price: $3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "      <td>Price: $3.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "      <td>Price: $3.6 million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "      <td>Price: $3.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "      <td>Price: $3.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "      <td>Price: $4.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "      <td>Price: $4.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Pagani Huayra Imola</td>\n",
       "      <td>Price: $5.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "      <td>Price: $5.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "      <td>Price: $5.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "      <td>Price: $6.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Mercedes-Maybach Exelero</td>\n",
       "      <td>Price: $7.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "      <td>Price: $8.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Bugatti Chiron Profilée</td>\n",
       "      <td>Price: $9.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Rolls-Royce Sweptail</td>\n",
       "      <td>Price: $10.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "      <td>Price: $12.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls-Royce Boat Tail*</td>\n",
       "      <td>Price: $13.4 Million</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Name                 Price\n",
       "0                     De Tomaso P72   Price: $1.3 Million\n",
       "1                 Ferrari LaFerrari   Price: $1.4 Million\n",
       "2                     Pagani Huayra   Price: $1.4 Million\n",
       "3                      McLaren Elva                      \n",
       "4                       Czinger 21C   Price: $1.7 Million\n",
       "5                     Ferrari Monza   Price: $1.7 Million\n",
       "6                Gordon Murray T.33   Price: $1.7 Million\n",
       "7                 Koenigsegg Gemera   Price: $1.7 Million\n",
       "8                       Zenvo TSR-S   Price: $1.7 Million\n",
       "9                Hennessey Venom F5   Price: $1.7 Million\n",
       "10                  Bentley Bacalar   Price: $1.8 Million\n",
       "11    Hispano Suiza Carmen Boulogne   Price: $1.9 Million\n",
       "12           Bentley Mulliner Batur   Price: $1.9 Million\n",
       "13                     Deus Vayanne   Price: $2.0 Million\n",
       "14                      SSC Tuatara   Price: $2.0 Million\n",
       "15                      Lotus Evija  Price: $2.0 Million*\n",
       "16              Aston Martin Vulcan   Price: $2.1 Million\n",
       "17                       Delage D12   Price: $2.3 Million\n",
       "18                McLaren Speedtail   Price: $2.3 Million\n",
       "19                     Rimac Nevera   Price: $2.3 Million\n",
       "20                    Pagani Utopia   Price: $2.4 Million\n",
       "21             Pininfarina Battista   Price: $2.5 Million\n",
       "22                Ferrari FXX K Evo   Price: $2.5 Million\n",
       "23               Gordon Murray T.50   Price: $2.6 Million\n",
       "24             Lamborghini Countach   Price: $2.6 Million\n",
       "25         Mercedes-AMG Project One   Price: $2.6 Million\n",
       "26              Aston Martin Victor   Price: $2.7 Million\n",
       "27      Hennessey Venom F5 Roadster   Price: $3.0 Million\n",
       "28                 Koenigsegg Jesko          $3.0 Million\n",
       "29            Aston Martin Valkyrie   Price: $3.0 Million\n",
       "30        W Motors Lykan Hypersport   Price: $3.2 Million\n",
       "31                    McLaren Solus   Price: $3.4 Million\n",
       "32        Pagani Huayra Roadster BC          $3.5 Million\n",
       "33         Bugatti Chiron Pur Sport   Price: $3.5 Million\n",
       "34                 Lamborghini Sian   Price: $3.6 Million\n",
       "35                 Koenigsegg CC850   Price: $3.6 million\n",
       "36  Bugatti Chiron Super Sport 300+   Price: $3.7 Million\n",
       "37               Lamborghini Veneno   Price: $3.9 Million\n",
       "38                   Bugatti Bolide   Price: $4.5 Million\n",
       "39                  Bugatti Mistral   Price: $4.7 Million\n",
       "40              Pagani Huayra Imola   Price: $5.0 Million\n",
       "41                     Bugatti Divo   Price: $5.4 Million\n",
       "42              SP Automotive Chaos   Price: $5.8 Million\n",
       "43                 Pagani Codalunga   Price: $6.4 Million\n",
       "44         Mercedes-Maybach Exelero   Price: $7.4 Million\n",
       "45               Bugatti Centodieci   Price: $8.0 Million\n",
       "46          Bugatti Chiron Profilée   Price: $9.0 Million\n",
       "47             Rolls-Royce Sweptail  Price: $10.8 Million\n",
       "48         Bugatti La Voiture Noire  Price: $12.8 Million\n",
       "49           Rolls-Royce Boat Tail*  Price: $13.4 Million"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Name':name, 'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4790b03c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
